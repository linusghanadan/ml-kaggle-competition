{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "db8f35d9-c3f3-4afd-acd4-e1e900a37bc6",
   "metadata": {},
   "source": [
    "# ML Kaggle Competition"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "931e1d19-1ce5-4691-98e3-49b5d0f58988",
   "metadata": {},
   "source": [
    "## Background\n",
    "\n",
    "We will use the data contained in the train.csv file to train a model that will predict **dissolved inorganic carbon (DIC)** content in water samples."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb9e527c-a503-4b2d-8057-2337741f2dc0",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "61266060-25da-43e3-ae3d-18179610ef67",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-21 06:21:57.676786: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-03-21 06:21:57.818745: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-03-21 06:21:57.823400: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /opt/R/4.2.2/lib/R/lib:/lib:/usr/local/lib:/usr/lib/x86_64-linux-gnu:/usr/lib/jvm/java-11-openjdk-amd64/lib/server\n",
      "2024-03-21 06:21:57.823414: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2024-03-21 06:21:58.441515: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /opt/R/4.2.2/lib/R/lib:/lib:/usr/local/lib:/usr/lib/x86_64-linux-gnu:/usr/lib/jvm/java-11-openjdk-amd64/lib/server\n",
      "2024-03-21 06:21:58.441596: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /opt/R/4.2.2/lib/R/lib:/lib:/usr/local/lib:/usr/lib/x86_64-linux-gnu:/usr/lib/jvm/java-11-openjdk-amd64/lib/server\n",
      "2024-03-21 06:21:58.441603: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "# load libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.regularizers import l1_l2\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from keras_tuner import HyperModel, RandomSearch\n",
    "from sklearn.model_selection import KFold\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a690f488-f26a-4b8a-bb8b-3a4d1cf0d1b7",
   "metadata": {},
   "source": [
    "## Import & pre-process training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bd63faaa-3be6-4ad9-afb1-f181c2c01bce",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1454 entries, 0 to 1453\n",
      "Data columns (total 19 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   id                 1454 non-null   int64  \n",
      " 1   lat_dec            1454 non-null   float64\n",
      " 2   lon_dec            1454 non-null   float64\n",
      " 3   no2um              1454 non-null   float64\n",
      " 4   no3um              1454 non-null   float64\n",
      " 5   nh3um              1454 non-null   float64\n",
      " 6   r_temp             1454 non-null   float64\n",
      " 7   r_depth            1454 non-null   int64  \n",
      " 8   r_sal              1454 non-null   float64\n",
      " 9   r_dynht            1454 non-null   float64\n",
      " 10  r_nuts             1454 non-null   float64\n",
      " 11  r_oxy_micromol.kg  1454 non-null   float64\n",
      " 12  unnamed:_12        0 non-null      float64\n",
      " 13  po4um              1454 non-null   float64\n",
      " 14  sio3um             1454 non-null   float64\n",
      " 15  ta1.x              1454 non-null   float64\n",
      " 16  salinity1          1454 non-null   float64\n",
      " 17  temperature_degc   1454 non-null   float64\n",
      " 18  dic                1454 non-null   float64\n",
      "dtypes: float64(17), int64(2)\n",
      "memory usage: 216.0 KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# import training data\n",
    "train_df = pd.read_csv('data/train.csv')\n",
    "train_df.columns = train_df.columns.str.lower().str.replace(' ', '_') # clean column names\n",
    "\n",
    "# inspect data\n",
    "print(train_df.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29c979c5-4b42-42e2-a9ab-8f45bf357cca",
   "metadata": {},
   "source": [
    "We will remove column 12 b/c there are 0 non-null values. We will also remove the 'id' column because we don't expect it to be a relevant predictor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "94680030-8307-4849-ad23-6173599e0393",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# remove 'id' and 'unnamed:_12' columns\n",
    "train_df = train_df.drop(['id', 'unnamed:_12'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "687f660a-8d08-48fa-bf2a-bead3ac1fb4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define feature matrix for training data\n",
    "X_train = train_df.drop('dic', axis=1).values\n",
    "\n",
    "# define target vector for training data\n",
    "y_train = train_df['dic'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd4ebd6b-d3ed-4b44-8f8d-9ef78203374d",
   "metadata": {},
   "source": [
    "## Build & train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8d3fec73-7b7b-463e-9e0c-da051438d567",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# initialize new HyperModel object\n",
    "class MyHyperModel:\n",
    "    \n",
    "    def __init__(self, input_shape):\n",
    "        self.input_shape = input_shape # store input shape as an instance attribute\n",
    "\n",
    "    def build(self, hp):\n",
    "        model = Sequential()\n",
    "        \n",
    "        # add dense layer with ReLU (based on preliminary training results)\n",
    "        model.add(Dense(units=hp['neurons_0'], # tune units (number of neurons)\n",
    "                        activation='relu', # select ReLU activator (based on preliminary training results)\n",
    "                        kernel_regularizer=l1_l2(l1=0.01, l2=0.01), # set L1 and L2\n",
    "                        input_shape=self.input_shape)) # specify input shape\n",
    "        \n",
    "        # add dense layer with ELU activator (based on preliminary training results)\n",
    "        model.add(Dense(units=hp['neurons_1'], # tune units (number of neurons)\n",
    "                        activation='elu', # select ELU activator (based on preliminary training results)\n",
    "                        kernel_regularizer=l1_l2(l1=0.01, l2=0.01))) # set L1 and L2\n",
    "        \n",
    "        # add dropout layer\n",
    "        model.add(Dropout(rate=hp['dropout_1'])) # tune dropout rate\n",
    "\n",
    "        # add 1 to 2 additional dense layers\n",
    "        for i in range(1, hp['num_layers']):\n",
    "            model.add(Dense(units=hp['neurons_2'], # tune units (number of neurons)\n",
    "                            activation=hp['activation'], # tune activation function\n",
    "                            kernel_regularizer=l1_l2(l1=0.01, l2=0.01))) # set L1 and L2\n",
    "            \n",
    "            # add 1 to 2 additional dropout layers\n",
    "            model.add(Dropout(hp['dropout_2']))  # tune dropout rate\n",
    "        \n",
    "        # add output layer with linear activation\n",
    "        model.add(Dense(1, activation='linear', kernel_regularizer=l1_l2(l1=0.01, l2=0.01)))\n",
    "        \n",
    "        # configure tuning for optimizer\n",
    "        optimizer = Adam(learning_rate=hp['learning_rate'], beta_1=hp['beta_1'])\n",
    "        \n",
    "        # compile hypermodel and set MSE as loss function\n",
    "        model.compile(optimizer=optimizer, loss='mean_squared_error')\n",
    "        \n",
    "        return model\n",
    "    \n",
    "# store HyperModel object with specified input shape based on number of columns in feature matrix\n",
    "hypermodel = MyHyperModel(input_shape=X_train.shape[1:])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eb4a6262-c035-4962-896e-220e9a196b57",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# create hyperparameter grid for tuning\n",
    "hyperparameter_grid = {\n",
    "    'neurons_0': [32, 64, 128, 256, 512],\n",
    "    'neurons_1': [32, 64, 128, 256, 512],\n",
    "    'dropout_1': [0.0, 0.1, 0.2, 0.3],\n",
    "    'num_layers': [2, 3],\n",
    "    'neurons_2': [32, 64, 128, 256, 512],\n",
    "    'activation': ['relu', 'elu'],\n",
    "    'dropout_2': [0.0, 0.1, 0.2, 0.3],\n",
    "    'learning_rate': [1e-5, 1e-4, 1e-3, 1e-2],\n",
    "    'beta_1': [0.7, 0.8, 0.9, 0.99]\n",
    "}\n",
    "\n",
    "# define function that creates all combinations of values stored in a dictionary\n",
    "def generate_combinations(grid):\n",
    "    keys, values = zip(*grid.items())\n",
    "    combinations = [dict(zip(keys, v)) for v in itertools.product(*values)]\n",
    "    return combinations\n",
    "\n",
    "# store all combinations of hyperparameter values from grid\n",
    "combinations = generate_combinations(hyperparameter_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "690df2c6-2f27-4b6f-971e-bffe828d17f0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-21 06:21:59.563380: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /opt/R/4.2.2/lib/R/lib:/lib:/usr/local/lib:/usr/lib/x86_64-linux-gnu:/usr/lib/jvm/java-11-openjdk-amd64/lib/server\n",
      "2024-03-21 06:21:59.563413: W tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:265] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2024-03-21 06:21:59.563432: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (taylor): /proc/driver/nvidia/version does not exist\n",
      "2024-03-21 06:21:59.563725: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41/41 [==============================] - 1s 5ms/step - loss: 5022045.0000\n",
      "Epoch 2/50\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 4958332.0000\n",
      "Epoch 3/50\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 4895076.5000\n",
      "Epoch 4/50\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 4832195.0000\n",
      "Epoch 5/50\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 4771112.0000\n",
      "Epoch 6/50\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 4711933.0000\n",
      "Epoch 7/50\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 4654552.0000\n",
      "Epoch 8/50\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 4598571.0000\n",
      "Epoch 9/50\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 4543545.0000\n",
      "Epoch 10/50\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 4489302.0000\n",
      "Epoch 11/50\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 4435681.0000\n",
      "Epoch 12/50\n",
      "41/41 [==============================] - 0s 3ms/step - loss: 4382601.5000\n",
      "Epoch 13/50\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 4330018.5000\n",
      "Epoch 14/50\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 4277885.0000\n",
      "Epoch 15/50\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 4226077.5000\n",
      "Epoch 16/50\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 4174555.2500\n",
      "Epoch 17/50\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 4123260.7500\n",
      "Epoch 18/50\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 4072167.2500\n",
      "Epoch 19/50\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 4021235.0000\n",
      "Epoch 20/50\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 3970432.7500\n",
      "Epoch 21/50\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 3919735.0000\n",
      "Epoch 22/50\n",
      "41/41 [==============================] - 0s 3ms/step - loss: 3869096.2500\n",
      "Epoch 23/50\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 3818485.0000\n",
      "Epoch 24/50\n",
      "41/41 [==============================] - 0s 3ms/step - loss: 3768015.0000\n",
      "Epoch 25/50\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 3718045.0000\n",
      "Epoch 26/50\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 3668129.0000\n",
      "Epoch 27/50\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 3618088.2500\n",
      "Epoch 28/50\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 3567901.0000\n",
      "Epoch 29/50\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 3517556.2500\n",
      "Epoch 30/50\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 3467035.7500\n",
      "Epoch 31/50\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 3416773.0000\n",
      "Epoch 32/50\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 3368198.2500\n",
      "Epoch 33/50\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 3321085.7500\n",
      "Epoch 34/50\n",
      "41/41 [==============================] - 0s 3ms/step - loss: 3274483.5000\n",
      "Epoch 35/50\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 3228121.7500\n",
      "Epoch 36/50\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 3181959.7500\n",
      "Epoch 37/50\n",
      "41/41 [==============================] - 0s 3ms/step - loss: 3136036.2500\n",
      "Epoch 38/50\n",
      "41/41 [==============================] - 0s 3ms/step - loss: 3090752.5000\n",
      "Epoch 39/50\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 3046051.0000\n",
      "Epoch 40/50\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 3001147.5000\n",
      "Epoch 41/50\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 2956173.7500\n",
      "Epoch 42/50\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 2911507.2500\n",
      "Epoch 43/50\n",
      "41/41 [==============================] - 0s 3ms/step - loss: 2867599.7500\n",
      "Epoch 44/50\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 2823918.5000\n",
      "Epoch 45/50\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 2780402.0000\n",
      "Epoch 46/50\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 2737153.0000\n",
      "Epoch 47/50\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 2694174.5000\n",
      "Epoch 48/50\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 2651480.0000\n",
      "Epoch 49/50\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 2608750.7500\n",
      "Epoch 50/50\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 2566219.2500\n",
      "Epoch 1/50\n",
      "41/41 [==============================] - 1s 4ms/step - loss: 7391382.5000\n",
      "Epoch 2/50\n",
      "41/41 [==============================] - 0s 3ms/step - loss: 7243236.5000\n",
      "Epoch 3/50\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 7096901.5000\n",
      "Epoch 4/50\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 6951402.0000\n",
      "Epoch 5/50\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 6810149.0000\n",
      "Epoch 6/50\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 6673302.5000\n",
      "Epoch 7/50\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 6544985.0000\n",
      "Epoch 8/50\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 6424647.0000\n",
      "Epoch 9/50\n",
      "41/41 [==============================] - 0s 3ms/step - loss: 6308636.0000\n",
      "Epoch 10/50\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 6195138.0000\n",
      "Epoch 11/50\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 6084462.5000\n",
      "Epoch 12/50\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 5979836.5000\n",
      "Epoch 13/50\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 5879635.5000\n",
      "Epoch 14/50\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 5778996.0000\n",
      "Epoch 15/50\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 5680830.0000\n",
      "Epoch 16/50\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 5585225.5000\n",
      "Epoch 17/50\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 5491412.5000\n",
      "Epoch 18/50\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 5398036.5000\n",
      "Epoch 19/50\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 5306202.5000\n",
      "Epoch 20/50\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 5218658.0000\n",
      "Epoch 21/50\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 5135079.5000\n",
      "Epoch 22/50\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 5054831.0000\n",
      "Epoch 23/50\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 4976936.5000\n",
      "Epoch 24/50\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 4901226.5000\n",
      "Epoch 25/50\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 4827687.0000\n",
      "Epoch 26/50\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 4756141.0000\n",
      "Epoch 27/50\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 4686203.0000\n",
      "Epoch 28/50\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 4617738.0000\n",
      "Epoch 29/50\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 4550881.5000\n",
      "Epoch 30/50\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 4485627.5000\n",
      "Epoch 31/50\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 4421753.0000\n",
      "Epoch 32/50\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 4359144.0000\n",
      "Epoch 33/50\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 4297453.0000\n",
      "Epoch 34/50\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 4236592.5000\n",
      "Epoch 35/50\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 4176368.0000\n",
      "Epoch 36/50\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 4116661.2500\n",
      "Epoch 37/50\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 4058767.2500\n",
      "Epoch 38/50\n",
      "41/41 [==============================] - 0s 3ms/step - loss: 4003090.5000\n",
      "Epoch 39/50\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 3950624.0000\n",
      "Epoch 40/50\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 3901358.2500\n",
      "Epoch 41/50\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 3853172.2500\n",
      "Epoch 42/50\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 3804921.2500\n",
      "Epoch 43/50\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 3756106.0000\n",
      "Epoch 44/50\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 3706136.7500\n",
      "Epoch 45/50\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 3654108.0000\n",
      "Epoch 46/50\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 3590867.5000\n",
      "Epoch 47/50\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 3522735.0000\n",
      "Epoch 48/50\n",
      "41/41 [==============================] - 0s 5ms/step - loss: 3459068.7500\n",
      "Epoch 49/50\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 3398070.7500\n",
      "Epoch 50/50\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 3339305.0000\n",
      "Epoch 1/50\n",
      "41/41 [==============================] - 1s 3ms/step - loss: 5381357.5000\n",
      "Epoch 2/50\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 5301550.5000\n",
      "Epoch 3/50\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 5223854.5000\n",
      "Epoch 4/50\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 5147510.5000\n",
      "Epoch 5/50\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 5071959.0000\n",
      "Epoch 6/50\n",
      "41/41 [==============================] - 0s 5ms/step - loss: 4996350.5000\n",
      "Epoch 7/50\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 4918267.5000\n",
      "Epoch 8/50\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 4837564.5000\n",
      "Epoch 9/50\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 4756353.5000\n",
      "Epoch 10/50\n",
      "41/41 [==============================] - 0s 5ms/step - loss: 4674539.5000\n",
      "Epoch 11/50\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 4592482.5000\n",
      "Epoch 12/50\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 4511759.0000\n",
      "Epoch 13/50\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 4432199.0000\n",
      "Epoch 14/50\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 4353647.0000\n",
      "Epoch 15/50\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 4276154.5000\n",
      "Epoch 16/50\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 4199639.0000\n",
      "Epoch 17/50\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 4124049.2500\n",
      "Epoch 18/50\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 4049404.0000\n",
      "Epoch 19/50\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 3975639.2500\n",
      "Epoch 20/50\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 3902453.0000\n",
      "Epoch 21/50\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 3827790.0000\n",
      "Epoch 22/50\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 3751312.0000\n",
      "Epoch 23/50\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 3675548.2500\n",
      "Epoch 24/50\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 3600188.2500\n",
      "Epoch 25/50\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 3525181.5000\n",
      "Epoch 26/50\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 3450480.2500\n",
      "Epoch 27/50\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 3376060.0000\n",
      "Epoch 28/50\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 3302000.0000\n",
      "Epoch 29/50\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 3228458.0000\n",
      "Epoch 30/50\n",
      "41/41 [==============================] - 0s 5ms/step - loss: 3155444.2500\n",
      "Epoch 31/50\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 3082902.5000\n",
      "Epoch 32/50\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 3010646.0000\n",
      "Epoch 33/50\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 2938615.2500\n",
      "Epoch 34/50\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 2866768.7500\n",
      "Epoch 35/50\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 2795094.5000\n",
      "Epoch 36/50\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 2723628.5000\n",
      "Epoch 37/50\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 2652366.0000\n",
      "Epoch 38/50\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 2581396.5000\n",
      "Epoch 39/50\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 2510821.7500\n",
      "Epoch 40/50\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 2440679.2500\n",
      "Epoch 41/50\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 2371101.2500\n",
      "Epoch 42/50\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 2302417.5000\n",
      "Epoch 43/50\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 2234479.5000\n",
      "Epoch 44/50\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 2167185.0000\n",
      "Epoch 45/50\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 2100553.7500\n",
      "Epoch 46/50\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 2034680.3750\n",
      "Epoch 47/50\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 1969765.0000\n",
      "Epoch 48/50\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 1905939.1250\n",
      "Epoch 49/50\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 1842023.5000\n",
      "Epoch 50/50\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 1773562.3750\n",
      "Epoch 1/50\n",
      "41/41 [==============================] - 1s 4ms/step - loss: 3832509.0000\n",
      "Epoch 2/50\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 3787269.5000\n",
      "Epoch 3/50\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 3741335.0000\n",
      "Epoch 4/50\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 3695987.0000\n",
      "Epoch 5/50\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 3651717.5000\n",
      "Epoch 6/50\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 3607898.7500\n",
      "Epoch 7/50\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 3564160.0000\n",
      "Epoch 8/50\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 3520063.0000\n",
      "Epoch 9/50\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 3475154.2500\n",
      "Epoch 10/50\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 3429648.5000\n",
      "Epoch 11/50\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 3383441.2500\n",
      "Epoch 12/50\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 3336763.5000\n",
      "Epoch 13/50\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 3289638.2500\n",
      "Epoch 14/50\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 3242206.2500\n",
      "Epoch 15/50\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 3194658.0000\n",
      "Epoch 16/50\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 3146941.2500\n",
      "Epoch 17/50\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 3099083.0000\n",
      "Epoch 18/50\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 3051090.0000\n",
      "Epoch 19/50\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 3002976.0000\n",
      "Epoch 20/50\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 2954707.5000\n",
      "Epoch 21/50\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 2906290.2500\n",
      "Epoch 22/50\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 2857710.5000\n",
      "Epoch 23/50\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 2808974.0000\n",
      "Epoch 24/50\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 2760085.7500\n",
      "Epoch 25/50\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 2711056.5000\n",
      "Epoch 26/50\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 2661848.5000\n",
      "Epoch 27/50\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 2612247.5000\n",
      "Epoch 28/50\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 2562635.2500\n",
      "Epoch 29/50\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 2513102.2500\n",
      "Epoch 30/50\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 2463589.0000\n",
      "Epoch 31/50\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 2414070.0000\n",
      "Epoch 32/50\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 2364564.2500\n",
      "Epoch 33/50\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 2315133.5000\n",
      "Epoch 34/50\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 2265755.7500\n",
      "Epoch 35/50\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 2216392.5000\n",
      "Epoch 36/50\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 2167078.2500\n",
      "Epoch 37/50\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 2117886.5000\n",
      "Epoch 38/50\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 2068809.7500\n",
      "Epoch 39/50\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 2019818.8750\n",
      "Epoch 40/50\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 1970953.0000\n",
      "Epoch 41/50\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 1922205.3750\n",
      "Epoch 42/50\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 1873593.5000\n",
      "Epoch 43/50\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 1825172.5000\n",
      "Epoch 44/50\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 1776985.8750\n",
      "Epoch 45/50\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 1729072.3750\n",
      "Epoch 46/50\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 1681447.1250\n",
      "Epoch 47/50\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 1634149.3750\n",
      "Epoch 48/50\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 1587202.0000\n",
      "Epoch 49/50\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 1540630.2500\n",
      "Epoch 50/50\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 1494454.7500\n",
      "Epoch 1/50\n",
      "41/41 [==============================] - 1s 4ms/step - loss: 5304910.0000\n",
      "Epoch 2/50\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 5252507.0000\n",
      "Epoch 3/50\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 5203022.0000\n",
      "Epoch 4/50\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 5155645.0000\n",
      "Epoch 5/50\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 5110016.5000\n",
      "Epoch 6/50\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 5065522.5000\n",
      "Epoch 7/50\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 5021948.0000\n",
      "Epoch 8/50\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 4979118.0000\n",
      "Epoch 9/50\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 4936715.5000\n",
      "Epoch 10/50\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 4894656.0000\n",
      "Epoch 11/50\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 4852916.0000\n",
      "Epoch 12/50\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 4811448.5000\n",
      "Epoch 13/50\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 4770788.0000\n",
      "Epoch 14/50\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 4731476.0000\n",
      "Epoch 15/50\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 4692696.0000\n",
      "Epoch 16/50\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 4654435.0000\n",
      "Epoch 17/50\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 4616586.5000\n",
      "Epoch 18/50\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 4578949.5000\n",
      "Epoch 19/50\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 4541493.5000\n",
      "Epoch 20/50\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 4504143.0000\n",
      "Epoch 21/50\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 4466688.0000\n",
      "Epoch 22/50\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 4428826.0000\n",
      "Epoch 23/50\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 4390582.0000\n",
      "Epoch 24/50\n",
      "41/41 [==============================] - 0s 5ms/step - loss: 4352148.5000\n",
      "Epoch 25/50\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 4313705.5000\n",
      "Epoch 26/50\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 4275301.5000\n",
      "Epoch 27/50\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 4236936.0000\n",
      "Epoch 28/50\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 4198577.0000\n",
      "Epoch 29/50\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 4160196.7500\n",
      "Epoch 30/50\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 4121737.7500\n",
      "Epoch 31/50\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 4083139.2500\n",
      "Epoch 32/50\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 4044303.7500\n",
      "Epoch 33/50\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 4005238.7500\n",
      "Epoch 34/50\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 3966039.2500\n",
      "Epoch 35/50\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 3926747.7500\n",
      "Epoch 36/50\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 3887379.0000\n",
      "Epoch 37/50\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 3847921.0000\n",
      "Epoch 38/50\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 3808367.0000\n",
      "Epoch 39/50\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 3768730.0000\n",
      "Epoch 40/50\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 3728978.2500\n",
      "Epoch 41/50\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 3689106.2500\n",
      "Epoch 42/50\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 3649111.5000\n",
      "Epoch 43/50\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 3609570.7500\n",
      "Epoch 44/50\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 3572451.2500\n",
      "Epoch 45/50\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 3536178.7500\n",
      "Epoch 46/50\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 3499896.0000\n",
      "Epoch 47/50\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 3463520.7500\n",
      "Epoch 48/50\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 3427564.7500\n",
      "Epoch 49/50\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 3392787.2500\n",
      "Epoch 50/50\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 3358066.7500\n",
      "Epoch 1/50\n",
      "41/41 [==============================] - 1s 4ms/step - loss: 3754683.7500\n",
      "Epoch 2/50\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 3677534.7500\n",
      "Epoch 3/50\n",
      "41/41 [==============================] - 0s 5ms/step - loss: 3601170.5000\n",
      "Epoch 4/50\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 3525413.0000\n",
      "Epoch 5/50\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 3450149.7500\n",
      "Epoch 6/50\n",
      "41/41 [==============================] - 0s 5ms/step - loss: 3375299.2500\n",
      "Epoch 7/50\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 3300819.5000\n",
      "Epoch 8/50\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 3226765.5000\n",
      "Epoch 9/50\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 3153077.0000\n",
      "Epoch 10/50\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 3079880.7500\n",
      "Epoch 11/50\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 3007361.0000\n",
      "Epoch 12/50\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 2935538.0000\n",
      "Epoch 13/50\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 2864103.2500\n",
      "Epoch 14/50\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 2793515.5000\n",
      "Epoch 15/50\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 2724225.7500\n",
      "Epoch 16/50\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 2655999.7500\n",
      "Epoch 17/50\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 2588590.5000\n",
      "Epoch 18/50\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 2521824.0000\n",
      "Epoch 19/50\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 2455373.0000\n",
      "Epoch 20/50\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 2389252.5000\n",
      "Epoch 21/50\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 2323660.0000\n",
      "Epoch 22/50\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 2258779.0000\n",
      "Epoch 23/50\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 2194814.0000\n",
      "Epoch 24/50\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 2131513.2500\n",
      "Epoch 25/50\n",
      "41/41 [==============================] - 0s 5ms/step - loss: 2069052.8750\n",
      "Epoch 26/50\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 2007359.0000\n",
      "Epoch 27/50\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 1946317.7500\n",
      "Epoch 28/50\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 1886069.8750\n",
      "Epoch 29/50\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 1826871.7500\n",
      "Epoch 30/50\n",
      "41/41 [==============================] - 0s 5ms/step - loss: 1768460.3750\n",
      "Epoch 31/50\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 1710767.6250\n",
      "Epoch 32/50\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 1653818.8750\n",
      "Epoch 33/50\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 1597614.5000\n",
      "Epoch 34/50\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 1542198.5000\n",
      "Epoch 35/50\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 1487577.1250\n",
      "Epoch 36/50\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 1433893.5000\n",
      "Epoch 37/50\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 1381283.1250\n",
      "Epoch 38/50\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 1329578.1250\n",
      "Epoch 39/50\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 1278765.1250\n",
      "Epoch 40/50\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 1228858.3750\n",
      "Epoch 41/50\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 1179853.6250\n",
      "Epoch 42/50\n",
      "41/41 [==============================] - 0s 5ms/step - loss: 1131771.6250\n",
      "Epoch 43/50\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 1084673.1250\n",
      "Epoch 44/50\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 1038569.1875\n",
      "Epoch 45/50\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 993472.9375\n",
      "Epoch 46/50\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 949420.1875\n",
      "Epoch 47/50\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 906410.6250\n",
      "Epoch 48/50\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 864469.5625\n",
      "Epoch 49/50\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 823598.3750\n",
      "Epoch 50/50\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 783837.5625\n",
      "Epoch 1/50\n",
      "41/41 [==============================] - 1s 4ms/step - loss: 3814640.5000\n",
      "Epoch 2/50\n",
      "41/41 [==============================] - 0s 3ms/step - loss: 3771257.5000\n",
      "Epoch 3/50\n",
      "41/41 [==============================] - 0s 3ms/step - loss: 3728285.5000\n",
      "Epoch 4/50\n",
      "41/41 [==============================] - 0s 3ms/step - loss: 3685919.0000\n",
      "Epoch 5/50\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 3644365.5000\n",
      "Epoch 6/50\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 3603715.7500\n",
      "Epoch 7/50\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 3563818.7500\n",
      "Epoch 8/50\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 3524553.2500\n",
      "Epoch 9/50\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 3485598.2500\n",
      "Epoch 10/50\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 3446718.7500\n",
      "Epoch 11/50\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 3407791.0000\n",
      "Epoch 12/50\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 3368794.5000\n",
      "Epoch 13/50\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 3329583.0000\n",
      "Epoch 14/50\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 3289969.2500\n",
      "Epoch 15/50\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 3250128.0000\n",
      "Epoch 16/50\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 3210055.5000\n",
      "Epoch 17/50\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 3169740.0000\n",
      "Epoch 18/50\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 3129183.5000\n",
      "Epoch 19/50\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 3088386.0000\n",
      "Epoch 20/50\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 3047343.0000\n",
      "Epoch 21/50\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 3006134.2500\n",
      "Epoch 22/50\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 2964805.7500\n",
      "Epoch 23/50\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 2923246.7500\n",
      "Epoch 24/50\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 2881446.5000\n",
      "Epoch 25/50\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 2839418.5000\n",
      "Epoch 26/50\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 2797154.2500\n",
      "Epoch 27/50\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 2754634.0000\n",
      "Epoch 28/50\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 2711812.0000\n",
      "Epoch 29/50\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 2668665.0000\n",
      "Epoch 30/50\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 2625244.2500\n",
      "Epoch 31/50\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 2581620.2500\n",
      "Epoch 32/50\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 2537706.2500\n",
      "Epoch 33/50\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 2492415.0000\n",
      "Epoch 34/50\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 2444936.5000\n",
      "Epoch 35/50\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 2397777.0000\n",
      "Epoch 36/50\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 2350749.5000\n",
      "Epoch 37/50\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 2303738.0000\n",
      "Epoch 38/50\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 2256738.5000\n",
      "Epoch 39/50\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 2209770.0000\n",
      "Epoch 40/50\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 2162820.7500\n",
      "Epoch 41/50\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 2115848.7500\n",
      "Epoch 42/50\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 2068787.2500\n",
      "Epoch 43/50\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 2021954.7500\n",
      "Epoch 44/50\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 1975649.2500\n",
      "Epoch 45/50\n",
      "41/41 [==============================] - 0s 3ms/step - loss: 1929809.7500\n",
      "Epoch 46/50\n",
      "41/41 [==============================] - 0s 3ms/step - loss: 1884308.2500\n",
      "Epoch 47/50\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 1839038.1250\n",
      "Epoch 48/50\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 1794024.0000\n",
      "Epoch 49/50\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 1749277.5000\n",
      "Epoch 50/50\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 1704809.3750\n",
      "Epoch 1/50\n",
      "41/41 [==============================] - 1s 4ms/step - loss: 6278790.5000\n",
      "Epoch 2/50\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 6174713.5000\n",
      "Epoch 3/50\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 6066942.5000\n",
      "Epoch 4/50\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 5959311.0000\n",
      "Epoch 5/50\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 5853354.5000\n",
      "Epoch 6/50\n",
      "41/41 [==============================] - 0s 3ms/step - loss: 5750970.0000\n",
      "Epoch 7/50\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 5652245.5000\n",
      "Epoch 8/50\n",
      "41/41 [==============================] - 0s 3ms/step - loss: 5556663.0000\n",
      "Epoch 9/50\n",
      "41/41 [==============================] - 0s 3ms/step - loss: 5461936.5000\n",
      "Epoch 10/50\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 5367041.5000\n",
      "Epoch 11/50\n",
      "41/41 [==============================] - 0s 3ms/step - loss: 5271941.0000\n",
      "Epoch 12/50\n",
      "41/41 [==============================] - 0s 3ms/step - loss: 5176975.5000\n",
      "Epoch 13/50\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 5083056.5000\n",
      "Epoch 14/50\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 4990136.0000\n",
      "Epoch 15/50\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 4898008.5000\n",
      "Epoch 16/50\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 4806575.5000\n",
      "Epoch 17/50\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 4715491.5000\n",
      "Epoch 18/50\n",
      "41/41 [==============================] - 0s 3ms/step - loss: 4624648.0000\n",
      "Epoch 19/50\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 4534502.5000\n",
      "Epoch 20/50\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 4445102.5000\n",
      "Epoch 21/50\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 4356476.5000\n",
      "Epoch 22/50\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 4268547.5000\n",
      "Epoch 23/50\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 4181194.5000\n",
      "Epoch 24/50\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 4094418.2500\n",
      "Epoch 25/50\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 4007986.5000\n",
      "Epoch 26/50\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 3921329.7500\n",
      "Epoch 27/50\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 3835071.7500\n",
      "Epoch 28/50\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 3749260.2500\n",
      "Epoch 29/50\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 3663554.5000\n",
      "Epoch 30/50\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 3578052.7500\n",
      "Epoch 31/50\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 3492969.5000\n",
      "Epoch 32/50\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 3407782.0000\n",
      "Epoch 33/50\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 3323095.5000\n",
      "Epoch 34/50\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 3238713.5000\n",
      "Epoch 35/50\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 3154407.0000\n",
      "Epoch 36/50\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 3070558.2500\n",
      "Epoch 37/50\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 2986395.0000\n",
      "Epoch 38/50\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 2901864.0000\n",
      "Epoch 39/50\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 2817348.0000\n",
      "Epoch 40/50\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 2733486.7500\n",
      "Epoch 41/50\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 2650143.7500\n",
      "Epoch 42/50\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 2567418.2500\n",
      "Epoch 43/50\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 2485849.7500\n",
      "Epoch 44/50\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 2405271.0000\n",
      "Epoch 45/50\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 2325852.5000\n",
      "Epoch 46/50\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 2247623.0000\n",
      "Epoch 47/50\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 2170589.0000\n",
      "Epoch 48/50\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 2094686.2500\n",
      "Epoch 49/50\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 2020009.3750\n",
      "Epoch 50/50\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 1946540.8750\n",
      "Epoch 1/50\n",
      "41/41 [==============================] - 1s 3ms/step - loss: 4880051.5000\n",
      "Epoch 2/50\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 4835287.5000\n",
      "Epoch 3/50\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 4788715.5000\n",
      "Epoch 4/50\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 4741457.0000\n",
      "Epoch 5/50\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 4697968.0000\n",
      "Epoch 6/50\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 4655999.5000\n",
      "Epoch 7/50\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 4614399.0000\n",
      "Epoch 8/50\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 4574033.5000\n",
      "Epoch 9/50\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 4535369.0000\n",
      "Epoch 10/50\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 4497102.0000\n",
      "Epoch 11/50\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 4459842.0000\n",
      "Epoch 12/50\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 4423417.0000\n",
      "Epoch 13/50\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 4387939.5000\n",
      "Epoch 14/50\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 4353248.5000\n",
      "Epoch 15/50\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 4319286.0000\n",
      "Epoch 16/50\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 4285755.5000\n",
      "Epoch 17/50\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 4252651.5000\n",
      "Epoch 18/50\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 4219687.5000\n",
      "Epoch 19/50\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 4186730.5000\n",
      "Epoch 20/50\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 4153732.7500\n",
      "Epoch 21/50\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 4120662.7500\n",
      "Epoch 22/50\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 4087483.2500\n",
      "Epoch 23/50\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 4054163.5000\n",
      "Epoch 24/50\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 4020679.0000\n",
      "Epoch 25/50\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 3986996.7500\n",
      "Epoch 26/50\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 3953099.5000\n",
      "Epoch 27/50\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 3919011.5000\n",
      "Epoch 28/50\n",
      "41/41 [==============================] - 0s 5ms/step - loss: 3884770.5000\n",
      "Epoch 29/50\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 3850747.7500\n",
      "Epoch 30/50\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 3816848.2500\n",
      "Epoch 31/50\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 3782777.2500\n",
      "Epoch 32/50\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 3748533.0000\n",
      "Epoch 33/50\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 3714162.2500\n",
      "Epoch 34/50\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 3679809.0000\n",
      "Epoch 35/50\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 3644527.7500\n",
      "Epoch 36/50\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 3604621.2500\n",
      "Epoch 37/50\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 3563208.2500\n",
      "Epoch 38/50\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 3519300.2500\n",
      "Epoch 39/50\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 3470567.2500\n",
      "Epoch 40/50\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 3415393.2500\n",
      "Epoch 41/50\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 3356089.5000\n",
      "Epoch 42/50\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 3297045.2500\n",
      "Epoch 43/50\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 3239397.5000\n",
      "Epoch 44/50\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 3182962.5000\n",
      "Epoch 45/50\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 3126937.7500\n",
      "Epoch 46/50\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 3072104.0000\n",
      "Epoch 47/50\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 3018506.5000\n",
      "Epoch 48/50\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 2965618.5000\n",
      "Epoch 49/50\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 2912879.0000\n",
      "Epoch 50/50\n",
      "41/41 [==============================] - 0s 3ms/step - loss: 2859250.7500\n",
      "Epoch 1/50\n",
      "41/41 [==============================] - 1s 4ms/step - loss: 5486563.0000\n",
      "Epoch 2/50\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 5407988.0000\n",
      "Epoch 3/50\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 5330618.0000\n",
      "Epoch 4/50\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 5254393.0000\n",
      "Epoch 5/50\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 5178944.5000\n",
      "Epoch 6/50\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 5104048.0000\n",
      "Epoch 7/50\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 5029878.0000\n",
      "Epoch 8/50\n",
      "41/41 [==============================] - 0s 3ms/step - loss: 4956130.0000\n",
      "Epoch 9/50\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 4882829.0000\n",
      "Epoch 10/50\n",
      "41/41 [==============================] - 0s 3ms/step - loss: 4809460.0000\n",
      "Epoch 11/50\n",
      "41/41 [==============================] - 0s 3ms/step - loss: 4736356.5000\n",
      "Epoch 12/50\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 4663986.0000\n",
      "Epoch 13/50\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 4592118.0000\n",
      "Epoch 14/50\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 4520159.5000\n",
      "Epoch 15/50\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 4447879.5000\n",
      "Epoch 16/50\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 4376205.0000\n",
      "Epoch 17/50\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 4304981.5000\n",
      "Epoch 18/50\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 4234097.0000\n",
      "Epoch 19/50\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 4163503.7500\n",
      "Epoch 20/50\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 4093176.7500\n",
      "Epoch 21/50\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 4022996.5000\n",
      "Epoch 22/50\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 3952843.5000\n",
      "Epoch 23/50\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 3882690.0000\n",
      "Epoch 24/50\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 3812748.2500\n",
      "Epoch 25/50\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 3743101.0000\n",
      "Epoch 26/50\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 3673739.2500\n",
      "Epoch 27/50\n",
      "41/41 [==============================] - 0s 5ms/step - loss: 3604677.5000\n",
      "Epoch 28/50\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 3535935.0000\n",
      "Epoch 29/50\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 3467566.7500\n",
      "Epoch 30/50\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 3399524.0000\n",
      "Epoch 31/50\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 3331767.7500\n",
      "Epoch 32/50\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 3264285.2500\n",
      "Epoch 33/50\n",
      "41/41 [==============================] - 0s 5ms/step - loss: 3197092.0000\n",
      "Epoch 34/50\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 3130156.0000\n",
      "Epoch 35/50\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 3063419.5000\n",
      "Epoch 36/50\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 2996883.0000\n",
      "Epoch 37/50\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 2930605.0000\n",
      "Epoch 38/50\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 2864606.2500\n",
      "Epoch 39/50\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 2798899.5000\n",
      "Epoch 40/50\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 2733491.2500\n",
      "Epoch 41/50\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 2668395.2500\n",
      "Epoch 42/50\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 2603607.7500\n",
      "Epoch 43/50\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 2539170.2500\n",
      "Epoch 44/50\n",
      "27/41 [==================>...........] - ETA: 0s - loss: 2491830.0000"
     ]
    }
   ],
   "source": [
    "# create EarlyStopping object to use when tuning hypermodel\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor='loss', # monitor loss function\n",
    "    min_delta=0.1, # set minimum decrease in loss function to be read as improvement\n",
    "    patience=10, # stop trial early if no improvement over 10 iterations\n",
    "    verbose=0, # disable verbose\n",
    "    mode='min', # specify that objective is to minimize function being monitored\n",
    "    restore_best_weights=True) # after early stopping, revert model weights to those from the epoch with the best value of the monitored metric\n",
    "\n",
    "# define custom function for performing a CV trial\n",
    "def cross_validate_combination(X, y, combination):\n",
    "    kf = KFold(n_splits=10) # initialize CV fold with 10 splits\n",
    "    val_scores = [] # initialize empty vector for validation scores\n",
    "    \n",
    "    for train_index, val_index in kf.split(X):\n",
    "        \n",
    "        # build model with combination of hyperparameters\n",
    "        model = hypermodel.build(combination)\n",
    "        \n",
    "        # build CV fold (with 10 splits) using all of training data\n",
    "        X_train_fold, X_val_fold = X[train_index], X[val_index]\n",
    "        y_train_fold, y_val_fold = y[train_index], y[val_index]\n",
    "        \n",
    "        # fit model to CV fold\n",
    "        model.fit(X_train_fold,\n",
    "                  y_train_fold,\n",
    "                  callbacks=[early_stopping], # use early stopping\n",
    "                  epochs=50, # set number of epochs for each trial\n",
    "                  verbose=0) # disable verbose\n",
    "        \n",
    "        # evaluate model performance\n",
    "        val_score = model.evaluate(X_val_fold,\n",
    "                                   y_val_fold,\n",
    "                                   verbose=0)\n",
    "        val_scores.append(val_score)\n",
    "    \n",
    "    # return average validation score across all 10 splits of CV fold\n",
    "    return np.mean(val_scores)\n",
    "\n",
    "# initialize objects for storing best CV score and best hyperparameter combination\n",
    "best_score = float('inf')\n",
    "best_combination = None\n",
    "\n",
    "# determine best hyperparameter combination based on CV score\n",
    "for combination in combinations:\n",
    "    score = cross_validate_combination(X_train,\n",
    "                                       y_train,\n",
    "                                       combination)\n",
    "    if score < best_score:\n",
    "        best_score = score\n",
    "        best_combination = combination\n",
    "print(\"Best Hyperparameters:\", best_combination)\n",
    "print(\"Best Score:\", best_score)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a186034e-885f-4e36-bc88-c2ed1a17eccb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# build version of hypermodel with best combination of hyperparameters\n",
    "best_model = hypermodel(best_combination, input_shape=X_train.shape[1:])\n",
    "\n",
    "# fit model to training data\n",
    "best_model.fit(X_train, y_train, epochs=100, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4a2600a-dae8-4105-8f5c-1bd406179f33",
   "metadata": {},
   "source": [
    "## Import & process testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4590eb9-73b0-4581-a19b-19f4f38e074f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import testing data\n",
    "test_df = pd.read_csv('data/test.csv')\n",
    "test_df.columns = train_df.columns.str.lower().str.replace(' ', '_') # clean column names\n",
    "\n",
    "# define feature matrix for testing data\n",
    "X_test = test_df.drop('dic', axis=1).values\n",
    "\n",
    "# remove 'id' and 'unnamed:_12' columns\n",
    "train_df = train_df.drop(['id', 'unnamed:_12'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf8da028-8430-46dc-8b44-35e05f7ce1f2",
   "metadata": {},
   "source": [
    "## Predict DIC for testing data & export submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfb62904-5714-4c56-8206-3c2d524b66e5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# generate predictions for testing data\n",
    "predictions = best_model.predict(X_test)\n",
    "\n",
    "# import submission template\n",
    "submission_df = pd.read_csv('data/sample_submission.csv')\n",
    "submission_df.columns = submission_df.columns.str.lower().str.replace(' ', '_')\n",
    "\n",
    "# bind predictions to 'dic' column\n",
    "submission_df['dic'] = predictions\n",
    "submission_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ed7a257-b0fb-4165-9a41-08331ee69b43",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# export submission\n",
    "submission_df.to_csv('linus_submission5.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.13",
   "language": "python",
   "name": "py3.7.13"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
