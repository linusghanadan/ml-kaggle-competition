{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "db8f35d9-c3f3-4afd-acd4-e1e900a37bc6",
   "metadata": {},
   "source": [
    "# ML Kaggle Competition"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "931e1d19-1ce5-4691-98e3-49b5d0f58988",
   "metadata": {},
   "source": [
    "## Background\n",
    "\n",
    "We will use the data contained in the train.csv file to train a model that will predict **dissolved inorganic carbon (DIC)** content in water samples."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb9e527c-a503-4b2d-8057-2337741f2dc0",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "61266060-25da-43e3-ae3d-18179610ef67",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-20 23:44:19.559460: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-03-20 23:44:19.670166: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-03-20 23:44:19.673847: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /opt/R/4.2.2/lib/R/lib:/lib:/usr/local/lib:/usr/lib/x86_64-linux-gnu:/usr/lib/jvm/java-11-openjdk-amd64/lib/server\n",
      "2024-03-20 23:44:19.673860: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2024-03-20 23:44:20.283517: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /opt/R/4.2.2/lib/R/lib:/lib:/usr/local/lib:/usr/lib/x86_64-linux-gnu:/usr/lib/jvm/java-11-openjdk-amd64/lib/server\n",
      "2024-03-20 23:44:20.283593: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /opt/R/4.2.2/lib/R/lib:/lib:/usr/local/lib:/usr/lib/x86_64-linux-gnu:/usr/lib/jvm/java-11-openjdk-amd64/lib/server\n",
      "2024-03-20 23:44:20.283600: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "# load libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import itertools\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.regularizers import l1_l2\n",
    "from keras_tuner import HyperModel\n",
    "from keras_tuner import RandomSearch\n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7d7fc6d5-b83e-4218-9ce3-dbdfb88fa3d7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Set the environment variable to change the log level\n",
    "#os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'  # 0 = default, 1 = no INFO, 2 = no INFO and WARNING, 3 = no INFO, WARNING, and ERROR"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a690f488-f26a-4b8a-bb8b-3a4d1cf0d1b7",
   "metadata": {},
   "source": [
    "## Import & pre-process training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bd63faaa-3be6-4ad9-afb1-f181c2c01bce",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1454 entries, 0 to 1453\n",
      "Data columns (total 19 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   id                 1454 non-null   int64  \n",
      " 1   lat_dec            1454 non-null   float64\n",
      " 2   lon_dec            1454 non-null   float64\n",
      " 3   no2um              1454 non-null   float64\n",
      " 4   no3um              1454 non-null   float64\n",
      " 5   nh3um              1454 non-null   float64\n",
      " 6   r_temp             1454 non-null   float64\n",
      " 7   r_depth            1454 non-null   int64  \n",
      " 8   r_sal              1454 non-null   float64\n",
      " 9   r_dynht            1454 non-null   float64\n",
      " 10  r_nuts             1454 non-null   float64\n",
      " 11  r_oxy_micromol.kg  1454 non-null   float64\n",
      " 12  unnamed:_12        0 non-null      float64\n",
      " 13  po4um              1454 non-null   float64\n",
      " 14  sio3um             1454 non-null   float64\n",
      " 15  ta1.x              1454 non-null   float64\n",
      " 16  salinity1          1454 non-null   float64\n",
      " 17  temperature_degc   1454 non-null   float64\n",
      " 18  dic                1454 non-null   float64\n",
      "dtypes: float64(17), int64(2)\n",
      "memory usage: 216.0 KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# import training data\n",
    "train_df = pd.read_csv('data/train.csv')\n",
    "train_df.columns = train_df.columns.str.lower().str.replace(' ', '_') # clean column names\n",
    "\n",
    "# inspect data\n",
    "print(train_df.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29c979c5-4b42-42e2-a9ab-8f45bf357cca",
   "metadata": {},
   "source": [
    "We will remove column 12 b/c there are 0 non-null values. We will also remove the 'id' column because we don't expect it to be a relevant predictor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "94680030-8307-4849-ad23-6173599e0393",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# remove 'id' and 'unnamed:_12' columns\n",
    "train_df = train_df.drop(['id', 'unnamed:_12'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "687f660a-8d08-48fa-bf2a-bead3ac1fb4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define feature matrix for training data\n",
    "X_train = train_df.drop('dic', axis=1).values\n",
    "\n",
    "# define target vector for training data\n",
    "y_train = train_df['dic'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd4ebd6b-d3ed-4b44-8f8d-9ef78203374d",
   "metadata": {},
   "source": [
    "## Build & train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "7d984819-4fe6-48c2-a0d2-3e6a490eaebc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# create EarlyStopping object to use when tuning hypermodel\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor='loss', # monitor loss function for all training data (as opposed to val_loss)\n",
    "    min_delta=0.01, # set minimum decrease in loss function to be read as improvement\n",
    "    patience=10, # stop trial early if no improvement over 10 iterations\n",
    "    verbose=1, # enable verbose (print a message for each epoch where the training is stopped early)\n",
    "    mode='min', # specify that objective is to minimize function being monitored\n",
    "    restore_best_weights=True # after early stopping, revert model weights to those from the epoch with the best value of the monitored metric\n",
    ")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "8d3fec73-7b7b-463e-9e0c-da051438d567",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# initialize new HyperModel object\n",
    "class MyHyperModel:\n",
    "    \n",
    "    def __init__(self, input_shape):\n",
    "        self.input_shape = input_shape # store input shape as an instance attribute\n",
    "\n",
    "    def build(self, hp):\n",
    "        model = Sequential()\n",
    "        \n",
    "        # add dense layer with ReLU (based on preliminary training results)\n",
    "        model.add(Dense(units=hp['neurons_0'], # tune units (number of neurons)\n",
    "                        activation='relu', # select ReLU activator (based on preliminary training results)\n",
    "                        kernel_regularizer=l1_l2(l1=0.01, l2=0.01), # set L1 and L2\n",
    "                        input_shape=self.input_shape)) # specify input shape\n",
    "        \n",
    "        # add dense layer with ELU activator (based on preliminary training results)\n",
    "        model.add(Dense(units=hp['neurons_1'], # tune units (number of neurons)\n",
    "                        activation='elu', # select ELU activator (based on preliminary training results)\n",
    "                        kernel_regularizer=l1_l2(l1=0.01, l2=0.01))) # set L1 and L2\n",
    "        \n",
    "        # add dropout layer\n",
    "        model.add(Dropout(rate=hp['dropout_1'])) # tune dropout rate\n",
    "\n",
    "        # add 1 to 2 additional dense layers\n",
    "        for i in range(1, hp['num_layers']):\n",
    "            model.add(Dense(units=hp['neurons_2'], # tune units (number of neurons)\n",
    "                            activation=hp['activation'], # tune activation function\n",
    "                            kernel_regularizer=l1_l2(l1=0.01, l2=0.01))) # set L1 and L2\n",
    "            \n",
    "            # add 1 to 2 additional dropout layers\n",
    "            model.add(Dropout(hp['dropout_2']))  # tune dropout rate\n",
    "        \n",
    "        # add output layer with linear activation\n",
    "        model.add(Dense(1, activation='linear', kernel_regularizer=l1_l2(l1=0.01, l2=0.01)))\n",
    "        \n",
    "        # configure tuning for optimizer\n",
    "        optimizer = Adam(learning_rate=hp['learning_rate'], beta_1=hp['beta_1'])\n",
    "        \n",
    "        # compile hypermodel and set MSE as loss function\n",
    "        model.compile(optimizer=optimizer, loss='mean_squared_error')\n",
    "        \n",
    "        return model\n",
    "    \n",
    "# store HyperModel object with specified input shape based on number of columns in feature matrix\n",
    "hypermodel = MyHyperModel(input_shape=X_train.shape[1:])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "eb4a6262-c035-4962-896e-220e9a196b57",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# create hyperparameter grid for tuning\n",
    "hyperparameter_grid = {\n",
    "    'neurons_0': [32, 64, 128, 256, 512],\n",
    "    'neurons_1': [32, 64, 128, 256, 512],\n",
    "    'dropout_1': [0.0, 0.1, 0.2, 0.3],\n",
    "    'num_layers': [2, 3],\n",
    "    'neurons_2': [32, 64, 128, 256, 512],\n",
    "    'activation': ['relu', 'elu'],\n",
    "    'dropout_2': [0.0, 0.1, 0.2, 0.3],\n",
    "    'learning_rate': [1e-5, 1e-4, 1e-3, 1e-2],\n",
    "    'beta_1': [0.7, 0.8, 0.9, 0.99]\n",
    "}\n",
    "\n",
    "# define function that creates all combinations of values stored in a dictionary\n",
    "def generate_combinations(grid):\n",
    "    keys, values = zip(*grid.items())\n",
    "    combinations = [dict(zip(keys, v)) for v in itertools.product(*values)]\n",
    "    return combinations\n",
    "\n",
    "# store all combinations of hyperparameter values from grid\n",
    "combinations = generate_combinations(hyperparameter_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "690df2c6-2f27-4b6f-971e-bffe828d17f0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# create EarlyStopping object to use when tuning hypermodel\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor='loss', # monitor loss function\n",
    "    min_delta=0.1, # set minimum decrease in loss function to be read as improvement\n",
    "    patience=10, # stop trial early if no improvement over 10 iterations\n",
    "    verbose=0, # disable verbose (print a message for each epoch where the training is stopped early)\n",
    "    mode='min', # specify that objective is to minimize function being monitored\n",
    "    restore_best_weights=True # after early stopping, revert model weights to those from the epoch with the best value of the monitored metric\n",
    ")\n",
    "\n",
    "# define custom function for performing a CV trial\n",
    "def cross_validate_combination(X, y, combination):\n",
    "    kf = KFold(n_splits=10) # initialize CV fold with 10 splits\n",
    "    val_scores = [] # initialize empty vector for validation scores\n",
    "    \n",
    "    for train_index, val_index in kf.split(X):\n",
    "        \n",
    "        # build model with combination of hyperparameters\n",
    "        model = hypermodel.build(combination)\n",
    "        \n",
    "        # build CV fold (with 10 splits) using all of training data\n",
    "        X_train_fold, X_val_fold = X[train_index], X[val_index]\n",
    "        y_train_fold, y_val_fold = y[train_index], y[val_index]\n",
    "        \n",
    "        # fit model to CV fold\n",
    "        model.fit(X_train_fold,\n",
    "                  y_train_fold,\n",
    "                  callbacks=[early_stopping], # use early stopping\n",
    "                  epochs=50, # set number of epochs for each trial\n",
    "                  verbose=1) # disable verbose (print a message for each epoch where the training is stopped early)\n",
    "        \n",
    "        # evaluate model performance\n",
    "        val_score = model.evaluate(X_val_fold, y_val_fold, verbose=1)\n",
    "        val_scores.append(val_score)\n",
    "    \n",
    "    # return average validation score across all 10 splits of CV fold\n",
    "    return np.mean(val_scores)\n",
    "\n",
    "# initialize objects for storing best CV score and best hyperparameter combination\n",
    "best_score = float('inf')\n",
    "best_combination = None\n",
    "\n",
    "# determine best hyperparameter combination based on CV score\n",
    "for combination in combinations:\n",
    "    score = cross_validate_combination(X_train, y_train, combination)\n",
    "    if score < best_score:\n",
    "        best_score = score\n",
    "        best_combination = combination\n",
    "print(\"Best Hyperparameters:\", best_combination)\n",
    "print(\"Best Score:\", best_score)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "c8f4c0f7-4f5d-4593-b82f-5a845cc949d9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_1107055/2201669192.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mcombination\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcombinations\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcross_validate_combination\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcombination\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mscore\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mbest_score\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0mbest_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_1107055/1389040801.py\u001b[0m in \u001b[0;36mcross_validate_combination\u001b[0;34m(X, y, combination)\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0mX_train_fold\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_val_fold\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mval_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0my_train_fold\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val_fold\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mval_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_fold\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train_fold\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mearly_stopping\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Customize as needed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m         \u001b[0mval_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_val_fold\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val_fold\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0mval_scores\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_score\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1648\u001b[0m                         ):\n\u001b[1;32m   1649\u001b[0m                             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1650\u001b[0;31m                             \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1651\u001b[0m                             \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1652\u001b[0m                                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    878\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    879\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 880\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    881\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    882\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    910\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    911\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 912\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_no_variable_creation_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    913\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variable_creation_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    914\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    133\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m    134\u001b[0m     return concrete_function._call_flat(\n\u001b[0;32m--> 135\u001b[0;31m         filtered_flat_args, captured_inputs=concrete_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m    136\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1744\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1745\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1746\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1747\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1748\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    381\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    382\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 383\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    384\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    385\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 53\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     54\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "best_score = float('inf')\n",
    "best_combination = None\n",
    "\n",
    "for combination in combinations:\n",
    "    score = cross_validate_combination(X_train, y_train, combination)\n",
    "    if score < best_score:\n",
    "        best_score = score\n",
    "        best_combination = combination\n",
    "\n",
    "print(\"Best Hyperparameters:\", best_combination)\n",
    "print(\"Best Score:\", best_score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a186034e-885f-4e36-bc88-c2ed1a17eccb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# build version of hypermodel with best combination of hyperparameters\n",
    "best_model = hypermodel(best_combination, input_shape=X_train.shape[1:])\n",
    "\n",
    "# fit model to training data\n",
    "best_model.fit(X_train, y_train, epochs=100, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4a2600a-dae8-4105-8f5c-1bd406179f33",
   "metadata": {},
   "source": [
    "## Import & process testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4590eb9-73b0-4581-a19b-19f4f38e074f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import testing data\n",
    "test_df = pd.read_csv('data/test.csv')\n",
    "test_df.columns = train_df.columns.str.lower().str.replace(' ', '_') # clean column names\n",
    "\n",
    "# define feature matrix for testing data\n",
    "X_test = test_df.drop('dic', axis=1).values\n",
    "\n",
    "# remove 'id' and 'unnamed:_12' columns\n",
    "train_df = train_df.drop(['id', 'unnamed:_12'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf8da028-8430-46dc-8b44-35e05f7ce1f2",
   "metadata": {},
   "source": [
    "## Predict DIC for testing data & export submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfb62904-5714-4c56-8206-3c2d524b66e5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# generate predictions for testing data\n",
    "predictions = best_model.predict(X_test)\n",
    "\n",
    "# import submission template\n",
    "submission_df = pd.read_csv('data/sample_submission.csv')\n",
    "submission_df.columns = submission_df.columns.str.lower().str.replace(' ', '_')\n",
    "\n",
    "# bind predictions to 'dic' column\n",
    "submission_df['dic'] = predictions\n",
    "submission_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ed7a257-b0fb-4165-9a41-08331ee69b43",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# export submission\n",
    "submission_df.to_csv('linus_submission5.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.13",
   "language": "python",
   "name": "py3.7.13"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
